{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" create datasets \"\"\"\n",
    "\n",
    "def create_dataset(examples_num):\n",
    "    \n",
    "    # create X dataset\n",
    "    X = np.random.rand(dataset_X_size[0], dataset_X_size[1])\n",
    "    X1 = X.copy()\n",
    "\n",
    "    # transform X into a dataset with only 0 & 1\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if X[i][j] < 0.5:\n",
    "                X1[i][j] = 0\n",
    "            else:\n",
    "                X1[i][j] = 1\n",
    "\n",
    "    # create Y XOR dataset\n",
    "    Y = np.logical_xor(X1[0], X1[1])\n",
    "\n",
    "#     X = np.random.randint(0, 2, size = (2, examples_num))\n",
    "\n",
    "#     Y = X.sum(axis=0, keepdims = True)  \n",
    "#     Y[Y != 1] = 0\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 100\n"
     ]
    }
   ],
   "source": [
    "dataset_X_size = (2,100)\n",
    "print(dataset_X_size[0], dataset_X_size[1])\n",
    "# X, Y = create_dataset(dataset_X_size)\n",
    "# print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" define mathematical activation function and their derivatives \"\"\"\n",
    "\n",
    "# relu function\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "# relu backward function / derivative\n",
    "def relu_back(dA):\n",
    "    dZ = np.array(dA, copy=True)       \n",
    "    dZ[dZ < 0] = 0\n",
    "    return dZ\n",
    "\n",
    "# sigmoid backward function / derivative\n",
    "def sigmoid_back(dA, A):\n",
    "    dZ = dA * (A * (1 - A))\n",
    "    assert dZ.shape == A.shape    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dedb6d7762a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# double check relu function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# double check sigmoid function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Z' is not defined"
     ]
    }
   ],
   "source": [
    "# double check relu function\n",
    "A = relu(Z)\n",
    "print (A)\n",
    "\n",
    "# double check sigmoid function\n",
    "A = sigmoid(Z)\n",
    "print(A)\n",
    "\n",
    "# double check relu backward function\n",
    "dA = np.sum(- np.divide(Y, A) + np.divide(1 - Y, 1 - A))\n",
    "dZ = relu_back(dA)\n",
    "print(dZ)\n",
    "\n",
    "# double check sigmoid backward function\n",
    "dZ = sigmoid_back(A)\n",
    "print (dZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 1 - initialize parameters \"\"\"\n",
    "\n",
    "def initialize_parameters(layer_dims):\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for i in range(1, L):\n",
    "        parameters['W'+str(i)] = np.random.randn(layer_dims[i], layer_dims[i-1]) * 0.01\n",
    "        parameters['b'+str(i)] = np.random.randn(layer_dims[i], 1)\n",
    "        \n",
    "        assert parameters['W'+str(i)].shape == (layer_dims[i], layer_dims[i-1])\n",
    "        assert parameters['b'+str(i)].shape == (layer_dims[i], 1)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bdefa47e59a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# double check initialize_parameters function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# double check initialize_parameters function\n",
    "parameters = initialize_parameters([len(X), 3, 3, 1])\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 2 - forward propagation \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# 2.1 - forward linear function\n",
    "\n",
    "def forward_linear(A, W, b):\n",
    "    \n",
    "    linear_cache = []\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    linear_cache = [A, W, b]\n",
    "    \n",
    "    assert Z.shape == (W.shape[0], A.shape[1])\n",
    "        \n",
    "    return Z, linear_cache\n",
    "\n",
    "\n",
    "\n",
    "# 2.2 - forward activation function\n",
    "\n",
    "def foward_activation(A_prev, W, b, activation):\n",
    "\n",
    "    activation_cache = []\n",
    "    cache = []\n",
    "    Z, linear_cache = forward_linear(A_prev, W, b)\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        A = relu(Z)\n",
    "    elif activation == 'sigmoid':\n",
    "        A = sigmoid(Z)\n",
    "    else:\n",
    "        print(\"activation function non-recognised\")\n",
    "        \n",
    "    assert A.shape == Z.shape\n",
    "    \n",
    "    activation_cache = [Z]\n",
    "    cache = (linear_cache, activation_cache)\n",
    "        \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "\n",
    "# 2.3 - forward propagation (L-layer)\n",
    "\n",
    "def forward_L_layer(X, parameters):\n",
    "    \n",
    "    caches = []\n",
    "    L = len(parameters) // 2\n",
    "    A_prev = X\n",
    "    \n",
    "    for i in range(1,L):\n",
    "        W = parameters['W' + str(i)]\n",
    "        b = parameters['b' + str(i)]\n",
    "        A_prev, cache = foward_activation(A_prev, W, b, activation='relu')\n",
    "        caches.append(cache)\n",
    "        \n",
    "    \n",
    "    W = parameters['W' + str(L)]\n",
    "    b = parameters['b' + str(L)]\n",
    "    A, cache = foward_activation(A_prev, W, b, activation='sigmoid')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return (A, caches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f01d8281d5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# double check forward linear function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(Z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# double check forward linear function\n",
    "\n",
    "Z, linear_cache = forward_linear(X, parameters['W1'], parameters['b1'])\n",
    "# print(Z)\n",
    "print(parameters['W1'])\n",
    "print(parameters['b1'])\n",
    "print(linear_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6217134cfb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# double check forward activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfoward_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(A, cache)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# double check forward activation function\n",
    "A_prev = X\n",
    "A, cache = foward_activation(A_prev, parameters['W1'], parameters['b1'], activation='sigmoid')\n",
    "# print(A, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f99f5ff39b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# double check forward propagation (L-layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_L_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# double check forward propagation (L-layer)\n",
    "\n",
    "A, caches = forward_L_layer(X, parameters)\n",
    "print(A)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 3 - cost function \"\"\"\n",
    "\n",
    "def cost_function(Y, A):\n",
    "\n",
    "    cost = 0\n",
    "    m = A.shape[1]\n",
    "    cost = - np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)) / m\n",
    "    \n",
    "#     J = np.squeeze(J)   \n",
    "#     assert J.shape == ()\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0e2bd414f863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# double check cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "# double check cost function\n",
    "\n",
    "J = cost_function(Y, A)\n",
    "print(type(J))\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 4 - backward propagation \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# 4.1 - backward linear function\n",
    "\n",
    "def back_linear(linear_cache, dZ):\n",
    "    \n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    dW = np.dot(dZ, A_prev.T) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "\n",
    "# 4.2 - backward activation function\n",
    "\n",
    "def back_activation(dA, A, caches, activation):\n",
    "    \n",
    "    linear_cache, activation_cache = caches\n",
    "    \n",
    "    if activation == 'relu_back':\n",
    "        dZ = relu_back(dA)\n",
    "    elif activation == 'sigmoid_back':\n",
    "        dZ = sigmoid_back(dA, A)\n",
    "    else:\n",
    "        print(\"activation function non-recognised\")\n",
    "        \n",
    "    dA_prev, dW, db = back_linear(linear_cache, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "\n",
    "# 4.3 - backward propagation (L-layer)\n",
    "\n",
    "def backward_L_layer(A, Y, caches):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    Y = Y.reshape(A.shape)\n",
    "    \n",
    "    dA = - np.divide(Y, A) + np.divide(1 - Y, 1 - A)\n",
    "\n",
    "    dA_prev, dW, db = back_activation(dA, A, caches[L-1], activation='sigmoid_back')\n",
    "#     grads['dA_prev'+str(L-1)] = dA_prev\n",
    "    grads['dW'+str(L)] = dW\n",
    "    grads['db'+str(L)] = db\n",
    "\n",
    "    \n",
    "    for i in reversed(range(L-1)):\n",
    "        dA_prev, dW_temps, db_temps = back_activation(dA_prev, A, caches[i], activation='relu_back')\n",
    "#         dA_prev, dW, db = back_activation(grads['dA_prev'+str(i+1)], A, caches[i], activation='relu_back')\n",
    "#         grads['dA_prev'+str(i)] = dA_prev\n",
    "        grads['dW'+str(i+1)] = dW_temps\n",
    "        grads['db'+str(i+1)] = db_temps\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bab8451e11b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# double check the whole backward propagation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_L_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "# double check the whole backward propagation function\n",
    "grads = backward_L_layer(A, Y, caches)\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 5 - update parameters function \"\"\"\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for i in range(L):\n",
    "\n",
    "        dW = grads['dW'+str(i+1)]\n",
    "        db = grads['db'+str(i+1)]\n",
    "        \n",
    "        parameters['W'+str(i+1)] -= learning_rate * dW\n",
    "        parameters['b'+str(i+1)] -= learning_rate * db\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-04a89c6af5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "print(parameters)\n",
    "learning_rate = 0.1\n",
    "parameters = update_parameters(parameters, grads, learning_rate)\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" running the DNN model by Channing\"\"\"\n",
    "\n",
    "def L_layer_DNN(dataset_X_size, iteration_num, layer_dims, learning_rate):\n",
    "\n",
    "    \n",
    "    # 1 - initialize parameter\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "#     print('parameters_initial: ', parameters)\n",
    "    \n",
    "    for i in range(iteration_num):\n",
    "\n",
    "        # 2 - forward propagation\n",
    "        A, caches = forward_L_layer(X, parameters)\n",
    "\n",
    "        # 3 - cost function \n",
    "        cost = cost_function(Y, A)\n",
    "\n",
    "        # 4 - backward propagation\n",
    "        grads = backward_L_layer(A, Y, caches)\n",
    "\n",
    "        # 5 - update parameters function\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "#         if i == iteration_num-1:\n",
    "#             print('parameters_updated: ', parameters)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print ('cost', i, ': ', cost)\n",
    "        \n",
    "#     return X, Y, parameters, A, caches, cost\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 0 :  0.9200686619626447\n",
      "cost 100 :  0.693027643761415\n",
      "cost 200 :  0.6930229955634869\n",
      "cost 300 :  0.6930186963632874\n",
      "cost 400 :  0.6930151772000709\n",
      "cost 500 :  0.6930125016885907\n",
      "cost 600 :  0.6930107386830942\n",
      "cost 700 :  0.6930099625951496\n",
      "cost 800 :  0.6930102536959802\n",
      "cost 900 :  0.6930116984179862\n",
      "cost 1000 :  0.6930143896561302\n",
      "cost 1100 :  0.6930184270662627\n",
      "cost 1200 :  0.6930239173571957\n",
      "cost 1300 :  0.6930309750425758\n",
      "cost 1400 :  0.6930397278067774\n",
      "cost 1500 :  0.6930503192001592\n",
      "cost 1600 :  0.6930628944745322\n",
      "cost 1700 :  0.6930776005932496\n",
      "cost 1800 :  0.6930945813748217\n",
      "cost 1900 :  0.6931139721210806\n",
      "cost 2000 :  0.693135912463427\n",
      "cost 2100 :  0.6931605690248612\n",
      "cost 2200 :  0.6931881336489256\n",
      "cost 2300 :  0.69321882369518\n",
      "cost 2400 :  0.6932528684877576\n",
      "cost 2500 :  0.6932905008785257\n",
      "cost 2600 :  0.6933319584875699\n",
      "cost 2700 :  0.6933776554561004\n",
      "cost 2800 :  0.6934285975398756\n",
      "cost 2900 :  0.6934859201981155\n"
     ]
    }
   ],
   "source": [
    "# create datasets\n",
    "examples_num = 400\n",
    "X, Y = create_dataset(dataset_X_size)\n",
    "\n",
    "# calling the DNN model\n",
    "iteration_num = 3000\n",
    "# layer_dims = [len(X), 4, 3, 1]\n",
    "layer_dims = [len(X), 100, 1]\n",
    "learning_rate = 0.01\n",
    "\n",
    "parameters = L_layer_DNN(examples_num, iteration_num, layer_dims, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
